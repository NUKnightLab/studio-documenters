{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring documents with LDA-based topic modeling\n",
    "\n",
    "Adapted from: https://stackabuse.com/python-for-nlp-topic-modeling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the docs\n",
    "\n",
    "Document loading is detailed in `clustering.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATADIR = '../data/DocumentCloud/subset'\n",
    "\n",
    "def documents(datadir=DATADIR):\n",
    "    for fn in os.listdir(datadir):\n",
    "        yield open(os.path.join(datadir, fn)).read()\n",
    "docs = [doc for doc in documents()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<380x3400 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38817 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(docs)\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "['service', 'vs', '2017', 'mr', 'complaints', '2018', 'bus', 'ada', 'ms', 'cta']\n",
      "\n",
      "\n",
      "Topic #1:\n",
      "['approve', 'regular', 'report', 'matters', 'authority', 'motion', 'chairman', 'transit', 'chicago', 'board']\n",
      "\n",
      "\n",
      "Topic #2:\n",
      "['stations', 'facilitator', 'complaints', 'work', 'members', 'cta', '2017', 'ms', '2016', 'station']\n",
      "\n",
      "\n",
      "Topic #3:\n",
      "['planning', 'delivery', 'strategic', '2018', 'approval', '2019', 'service', 'agenda', 'business', 'minutes']\n",
      "\n",
      "\n",
      "Topic #4:\n",
      "['agreement', 'review', 'finance', 'motion', 'number', 'authorizing', 'contract', 'ordinance', '000', '00']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA.fit(doc_term_matrix)\n",
    "\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
