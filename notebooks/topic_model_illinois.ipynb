{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbXAJnld0veS"
   },
   "source": [
    "# Topic modeling with tmtoolkit\n",
    "\n",
    "Adapted from: https://github.com/WZBSocialScienceCenter/tmtoolkit/blob/master/doc/source/topic_modeling.ipynb\n",
    "\n",
    "## An example document-term matrix\n",
    "\n",
    "tmtoolkit supports topic models that are computed from document-term matrices (DTMs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tmtoolkit[gensim,lda,recommended,sklearn]\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/4b/03d1620dc30f99bb03bbcebcb93795f88a49e5875756ebc3871092f04e82/tmtoolkit-0.9.0-py3-none-any.whl (19.9MB)\n",
      "\u001b[K     |████████████████████████████████| 19.9MB 23.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting deprecation>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/2a/d5084a8781398cea745c01237b95d9762c382697c63760a95cc6a814ad3a/deprecation-2.0.7-py2.py3-none-any.whl\n",
      "Collecting matplotlib>=3.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/07/4b361d6d0f4e08942575f83a11d33f36897e1aae4279046606dd1808778a/matplotlib-3.1.3-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1MB 78.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk>=3.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 81.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting germalemma>=0.1.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/94/b335fa67ec8dd6fca977769c17f657526f66e0bcb3a10f44f890ea16555a/germalemma-0.1.3-py3-none-any.whl (2.3MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 77.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tmtoolkit[gensim,lda,recommended,sklearn]) (1.3.1)\n",
      "Collecting pandas>=0.25.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/ec/b5dd8cfb078380fb5ae9325771146bccd4e8cad2d3e4c72c7433010684eb/pandas-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1MB 74.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting globre>=0.1.5\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/ce/a9e2f3317a458f8c591a1f95d4061d4e241f529ba678292acdcf2d804783/globre-0.1.5.tar.gz\n",
      "Collecting numpy>=1.17.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2MB 82.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xlrd>=1.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl (103kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 85.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gensim>=3.8.0; extra == \"gensim\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/112bd4258cee11e0baaaba064060eb156475a42362e59e3ff28e7ca2d29d/gensim-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2MB 93.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lda>=1.1.0; extra == \"lda\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/27/d62628d914bff7f048e2b433c3adea9e7072fa20028f1d4194999051cd9d/lda-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (348kB)\n",
      "\u001b[K     |████████████████████████████████| 358kB 86.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting openpyxl>=3.0.0; extra == \"recommended\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8c/83563c60489954e5b80f9e2596b93a68e1ac4e4a730deb1aae632066d704/openpyxl-3.0.3.tar.gz (172kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 87.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Pillow>=6.2.0; extra == \"recommended\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/5e/23dcc0ce3cc2abe92efd3cd61d764bee6ccdf1b667a1fb566f45dc249953/Pillow-7.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 84.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wordcloud>=1.6.0; extra == \"recommended\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/f3/1017ea53d88cf39cc06139be4e021d99e3972d6cf635c8598c4cbecbbed0/wordcloud-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (361kB)\n",
      "\u001b[K     |████████████████████████████████| 368kB 93.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn>=0.22; extra == \"sklearn\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1MB 63.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from deprecation>=2.0.0->tmtoolkit[gensim,lda,recommended,sklearn]) (20.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=3.1.0->tmtoolkit[gensim,lda,recommended,sklearn]) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=3.1.0->tmtoolkit[gensim,lda,recommended,sklearn]) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=3.1.0->tmtoolkit[gensim,lda,recommended,sklearn]) (2.7.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=3.1.0->tmtoolkit[gensim,lda,recommended,sklearn]) (1.0.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from nltk>=3.4.0->tmtoolkit[gensim,lda,recommended,sklearn]) (1.11.0)\n",
      "Collecting PatternLite>=3.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/f5/1894eb24102cae0e433c18366ec2a8d945b42cbf128303b67454db8587d8/PatternLite-3.6-py3-none-any.whl (22.1MB)\n",
      "\u001b[K     |████████████████████████████████| 22.1MB 63.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Pyphen>=0.9.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/82/08a3629dce8d1f3d91db843bb36d4d7db6b6269d5067259613a0d5c8a9db/Pyphen-0.9.5-py2.py3-none-any.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 61.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.25.0->tmtoolkit[gensim,lda,recommended,sklearn]) (2018.4)\n",
      "Collecting smart-open>=1.8.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/09/735f2786dfac9bbf39d244ce75c0313d27d4962e71e0774750dc809f2395/smart_open-1.9.0.tar.gz (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 17.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pbr<4,>=0.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/5d/b077dbf309993d52c1d71e6bf6fe443a8029ea215135ebbe0b1b10e7aefc/pbr-3.1.1-py2.py3-none-any.whl (99kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 22.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jdcal in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from openpyxl>=3.0.0; extra == \"recommended\"->tmtoolkit[gensim,lda,recommended,sklearn]) (1.4)\n",
      "Requirement already satisfied: et_xmlfile in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from openpyxl>=3.0.0; extra == \"recommended\"->tmtoolkit[gensim,lda,recommended,sklearn]) (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-learn>=0.22; extra == \"sklearn\"->tmtoolkit[gensim,lda,recommended,sklearn]) (0.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.0->tmtoolkit[gensim,lda,recommended,sklearn]) (41.6.0)\n",
      "Requirement already satisfied: boto>=2.32 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim>=3.8.0; extra == \"gensim\"->tmtoolkit[gensim,lda,recommended,sklearn]) (2.48.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim>=3.8.0; extra == \"gensim\"->tmtoolkit[gensim,lda,recommended,sklearn]) (2.20.0)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim>=3.8.0; extra == \"gensim\"->tmtoolkit[gensim,lda,recommended,sklearn]) (1.11.14)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim>=3.8.0; extra == \"gensim\"->tmtoolkit[gensim,lda,recommended,sklearn]) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim>=3.8.0; extra == \"gensim\"->tmtoolkit[gensim,lda,recommended,sklearn]) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim>=3.8.0; extra == \"gensim\"->tmtoolkit[gensim,lda,recommended,sklearn]) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim>=3.8.0; extra == \"gensim\"->tmtoolkit[gensim,lda,recommended,sklearn]) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.8.0; extra == \"gensim\"->tmtoolkit[gensim,lda,recommended,sklearn]) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.8.0; extra == \"gensim\"->tmtoolkit[gensim,lda,recommended,sklearn]) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.14 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.8.0; extra == \"gensim\"->tmtoolkit[gensim,lda,recommended,sklearn]) (1.14.14)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.14->boto3->smart-open>=1.8.1->gensim>=3.8.0; extra == \"gensim\"->tmtoolkit[gensim,lda,recommended,sklearn]) (0.14)\n",
      "Building wheels for collected packages: nltk, globre, openpyxl, smart-open\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449373 sha256=f214448a9f510533f0302faf319c8e41e62c79d1f84625bba076e2e4e14d15fe\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "  Building wheel for globre (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for globre: filename=globre-0.1.5-cp36-none-any.whl size=8161 sha256=a44b90c5df01d78e6c3c4c6d1b15605956ef320f9b43c7ef38833f55417dfd35\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c4/3f/7f/be546f6d880521a8a7a1fe84cbe135fa859be63084682d3292\n",
      "  Building wheel for openpyxl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openpyxl: filename=openpyxl-3.0.3-py2.py3-none-any.whl size=241277 sha256=09b9e04e28486096706d177861061ed7b783716026a156da7124e124324bf8a3\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/b5/85/ca/e768ac132e57e75e645a151f8badac71cc0089e7225dddf76b\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-1.9.0-cp36-none-any.whl size=72258 sha256=c7b531a4efdd544564ba5cec8970785ab093f2dd634d4c2f147e6025d1d88bcc\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/ab/10/93/5cff86f5b721d77edaecc29959b1c60d894be1f66d91407d28\n",
      "Successfully built nltk globre openpyxl smart-open\n",
      "Installing collected packages: deprecation, numpy, matplotlib, nltk, PatternLite, Pyphen, germalemma, pandas, globre, xlrd, smart-open, gensim, pbr, lda, openpyxl, Pillow, wordcloud, scikit-learn, tmtoolkit\n",
      "  Found existing installation: numpy 1.16.4\n",
      "    Uninstalling numpy-1.16.4:\n",
      "      Successfully uninstalled numpy-1.16.4\n",
      "  Found existing installation: matplotlib 3.0.3\n",
      "    Uninstalling matplotlib-3.0.3:\n",
      "      Successfully uninstalled matplotlib-3.0.3\n",
      "  Found existing installation: nltk 3.3\n",
      "    Uninstalling nltk-3.3:\n",
      "      Successfully uninstalled nltk-3.3\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "  Found existing installation: xlrd 1.1.0\n",
      "    Uninstalling xlrd-1.1.0:\n",
      "      Successfully uninstalled xlrd-1.1.0\n",
      "  Found existing installation: openpyxl 2.5.3\n",
      "    Uninstalling openpyxl-2.5.3:\n",
      "      Successfully uninstalled openpyxl-2.5.3\n",
      "  Found existing installation: Pillow 5.2.0\n",
      "    Uninstalling Pillow-5.2.0:\n",
      "      Successfully uninstalled Pillow-5.2.0\n",
      "  Found existing installation: scikit-learn 0.21.3\n",
      "    Uninstalling scikit-learn-0.21.3:\n",
      "      Successfully uninstalled scikit-learn-0.21.3\n",
      "Successfully installed PatternLite-3.6 Pillow-7.0.0 Pyphen-0.9.5 deprecation-2.0.7 gensim-3.8.1 germalemma-0.1.3 globre-0.1.5 lda-1.1.0 matplotlib-3.1.3 nltk-3.4.5 numpy-1.18.1 openpyxl-3.0.3 pandas-1.0.1 pbr-3.1.1 scikit-learn-0.22.1 smart-open-1.9.0 tmtoolkit-0.9.0 wordcloud-1.6.0 xlrd-1.2.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import tmtoolkit\n",
    "except ModuleNotFoundError:\n",
    "    !pip install tmtoolkit[recommended,lda,sklearn,gensim]\n",
    "from tmtoolkit.topicmod import tm_lda\n",
    "from tmtoolkit.topicmod.model_io import print_ldamodel_topic_words\n",
    "from tmtoolkit.topicmod.tm_lda import compute_models_parallel\n",
    "from tmtoolkit.topicmod.tm_lda import evaluate_topic_models\n",
    "from tmtoolkit.topicmod.evaluate import results_by_parameter\n",
    "from tmtoolkit.corpus import Corpus\n",
    "from tmtoolkit.preprocess import TMPreproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uquaYEIC0vea",
    "outputId": "cf55d7dd-7d7d-43f3-d149-b529257abe91",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Corpus [17237 documents]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(20191120)   # to make the sampling reproducible\n",
    "np.set_printoptions(precision=5)\n",
    "\n",
    "DATADIR = 'data/documenters/illinois'\n",
    "_corpus = Corpus()\n",
    "\n",
    "\n",
    "def documents(datadir=DATADIR):\n",
    "    for fn in os.listdir(datadir):\n",
    "        yield fn, open(os.path.join(datadir, fn)).read()\n",
    "\n",
    "for fn, text in documents():\n",
    "    _corpus.add_doc(fn[:-4], text)\n",
    "\n",
    "_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "id": "VkYKc8LhGAMR",
    "outputId": "cb1112b9-0a37-458f-91d7-5a07c74359a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.6794e+04, 2.8100e+02, 1.0700e+02, 3.6000e+01, 1.3000e+01,\n",
       "        4.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([      0. ,  217464.5,  434929. ,  652393.5,  869858. , 1087322.5,\n",
       "        1304787. , 1522251.5, 1739716. , 1957180.5, 2174645. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.pyplot.hist(_corpus.doc_lengths.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Ainw8SuLGwWl",
    "outputId": "3c62cfe8-b9cf-46c4-82c9-15a43ed09c78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean doc length: 27797.95039740094\n",
      "Std: 79844.54599522066\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, stdev\n",
    "doclen_mean = mean(_corpus.doc_lengths.values())\n",
    "doclen_std = stdev(_corpus.doc_lengths.values())\n",
    "print('Mean doc length:', doclen_mean)\n",
    "print('Std:', doclen_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HyR3svJQHQXy",
    "outputId": "9670823e-f730-4a48-9cf6-afcec886cc3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Corpus [16279 documents]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For topic modeling, document sizes should be similar.\n",
    "# If there is a lot of variance, we might look at a subset of documents of similar size\n",
    "_corpus = _corpus.filter_by_max_length(doclen_mean + doclen_std)\n",
    "_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qypuHbTlK706"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Corpus [5000 documents]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A large corpus can be heavy to process. Here we take a sample of 5000 docs\n",
    "corpus = _corpus.sample(5000)\n",
    "corpus.filter_characters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    import nltk\n",
    "except ModuleNotFoundError:\n",
    "    !pip install nltk\n",
    "    import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QpqtMtLf0vfO"
   },
   "source": [
    "## Pre-process the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pNdROi_d0vfR",
    "outputId": "60cc432c-540e-4b5e-a60b-7f6579f191e6",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4348)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc = TMPreproc(corpus)\n",
    "preproc = preproc \\\n",
    "    .tokens_to_lowercase() \\\n",
    "    .remove_special_chars_in_tokens() \\\n",
    "    .add_stopwords(['mr', 'mrs', 'ms']) \\\n",
    "    .clean_tokens(\n",
    "        remove_numbers=True,\n",
    "        remove_shorter_than=3,\n",
    "        remove_longer_than=20\n",
    "    ) \\\n",
    "    .remove_common_tokens(df_threshold=0.85) \\\n",
    "    .remove_uncommon_tokens(df_threshold=0.01)\n",
    "    \n",
    "    #.remove_common_tokens(df_threshold=0.001) \\\n",
    "    #.remove_uncommon_tokens(df_threshold=0.8)\n",
    "preproc.pos_tag()\n",
    "preproc.filter_for_pos(['N', 'V'])\n",
    "preproc.lemmatize()\n",
    "preproc.n_docs, preproc.vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>position</th>\n",
       "      <th>token</th>\n",
       "      <th>meta_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5015759-Agenda</td>\n",
       "      <td>0</td>\n",
       "      <td>city</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5015759-Agenda</td>\n",
       "      <td>1</td>\n",
       "      <td>downtown</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5015759-Agenda</td>\n",
       "      <td>2</td>\n",
       "      <td>development</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5015759-Agenda</td>\n",
       "      <td>3</td>\n",
       "      <td>authority</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5015759-Agenda</td>\n",
       "      <td>4</td>\n",
       "      <td>floor</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>6570808-Special-Meeting-2019-12-12-Agenda</td>\n",
       "      <td>223</td>\n",
       "      <td>water</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>6570808-Special-Meeting-2019-12-12-Agenda</td>\n",
       "      <td>224</td>\n",
       "      <td>reclamation</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>6570808-Special-Meeting-2019-12-12-Agenda</td>\n",
       "      <td>225</td>\n",
       "      <td>district</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>6570808-Special-Meeting-2019-12-12-Agenda</td>\n",
       "      <td>226</td>\n",
       "      <td>page</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>6570808-Special-Meeting-2019-12-12-Agenda</td>\n",
       "      <td>227</td>\n",
       "      <td>print</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3732262 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           doc  position        token meta_pos\n",
       "0                               5015759-Agenda         0         city       NN\n",
       "1                               5015759-Agenda         1     downtown       NN\n",
       "2                               5015759-Agenda         2  development       NN\n",
       "3                               5015759-Agenda         3    authority       NN\n",
       "4                               5015759-Agenda         4        floor       NN\n",
       "..                                         ...       ...          ...      ...\n",
       "223  6570808-Special-Meeting-2019-12-12-Agenda       223        water       NN\n",
       "224  6570808-Special-Meeting-2019-12-12-Agenda       224  reclamation       NN\n",
       "225  6570808-Special-Meeting-2019-12-12-Agenda       225     district       NN\n",
       "226  6570808-Special-Meeting-2019-12-12-Agenda       226         page       NN\n",
       "227  6570808-Special-Meeting-2019-12-12-Agenda       227        print      VBD\n",
       "\n",
       "[3732262 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.tokens_datatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4B68dNG0vfy"
   },
   "source": [
    "## Create document labels array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "gvTU-DSK0vfz",
    "outputId": "adf1d30d-c285-4452-a156-65e93d09e00a",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5015759-Agenda', '5015774-Minutes', '5015821-Agenda',\n",
       "       '5015824-Agenda', '5015839-Agenda', '5015857-Meeting-Notice',\n",
       "       '5015859-Committee-on-Finance-Audit-amp-Budget-2018-10-10',\n",
       "       '5015860-Regular-Commission-Meeting-2018-08-23-Minutes',\n",
       "       '5015867-Employee-Retirement-Review-Committee-Meeting',\n",
       "       '5015872-Zoning-Board-of-Appeals-2017-01-20-Minutes'], dtype='<U58')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_labels = np.array(preproc.doc_labels)\n",
    "doc_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Document-term-matrix and the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "wi1B_0eS0vgG",
    "outputId": "0db78dff-6d2d-4222-e469-7f83657981de",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "vocab = np.array(preproc.vocabulary)\n",
    "dtm = preproc.dtm\n",
    "\n",
    "del preproc # once we have the dtm, we no longer need the preprocessed corpus\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4-47yr2q0vgQ"
   },
   "source": [
    "We now have a sparse DTM, a list of document labels `doc_labels` that represent the rows of both DTMs and vocabulary array `vocab` that represent the columns of the DTM. We will use this data for the remainder of the notebook.\n",
    "\n",
    "### suppress unwanted logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "kOZpg0YA0vgW",
    "outputId": "b5627eaa-bb62-4508-b7bc-a463322ec6c4",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('lda')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4xeB9t5Q0vhR"
   },
   "source": [
    "## Evaluation of topic model\n",
    "\n",
    "tmtoolkit provides several metrics for comparing and evaluating topic models. This can be used for finding a good hyperparameter set for a given dataset, e.g. a good combination of the number of topics and concentration paramaters (often called alpha and beta in literature). For some background on hyperparameters in topic modeling, see [this blog post](https://datascience.blog.wzb.eu/2017/11/09/topic-modeling-evaluation-in-python-with-tmtoolkit/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1-G-tLi0vhg"
   },
   "source": [
    "The heart of the model evaluation process is the function [evaluate_topic_models()](api.rst#tmtoolkit.topicmod.tm_lda.evaluate_topic_models), which is available for all three topic modeling packages. We stick with lda and import that function from [topicmod.tm_lda](api.rst#module-tmtoolkit.topicmod.tm_lda). It is similar to [compute_models_parallel()](api.rst#tmtoolkit.topicmod.tm_lda.compute_models_parallel) as it accepts varying and constant hyperparameters. However, it doesn't only compute the models in parallel, but also applies several metrics to these models in order to evaluate them. This can be controlled with the `metric` parameter that accepts a string or a list of strings that specify the used metric(s). These metrics refer to functions that are implemented in [topicmod.evaluate](api.rst#module-tmtoolkit.topicmod.evaluate).\n",
    "\n",
    "Each topic modeling sub-module defines two important sequences: `AVAILABLE_METRICS` and `DEFAULT_METRICS`. The former lists all available metrics for that sub-module, the latter lists the default metrics that are used when you don't specify anything with the `metric` parameter. Let's have a look at both sequences in [topicmod.tm_lda](api.rst#module-tmtoolkit.topicmod.tm_lda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "-J6xa1Ka0vhj",
    "outputId": "f40f506e-bfc6-4cdf-81f3-1f7fa212e546",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tm_lda.AVAILABLE_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ztxVyDIV0vhq",
    "outputId": "aa805b71-4c50-438f-81e6-ef4623292faf",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tm_lda.DEFAULT_METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0dvRY-r0vh2"
   },
   "source": [
    "For details about the metrics and the academic references, see the respective implementations in the [topicmod.evaluate](api.rst#module-tmtoolkit.topicmod.evaluate) module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_params = [{'n_topics': k, 'alpha': 1/(10**k), 'eta':0.001 } for k in range(1, 201, 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_params = {\n",
    "    'n_iter': 100,\n",
    "    'random_state': 20191122  # to make results reproducible\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "We will now run the model evaluations with [evaluate_topic_models()](api.rst#tmtoolkit.topicmod.tm_lda.evaluate_topic_models). For each candidate hyperparameter set, a model can be generated and evaluated in parallel. We will do this now for the DTM. Our candidate values for the number of topics k. We make alpha and beta vary with respect to k. We also set `return_models=True` which means to retain the generated models in the evaluation results.\n",
    "\n",
    "This step will take some time, depending on the corpus size, vocabulary size, number of steps in var_params, the number of iterations calculated.\n",
    "\n",
    "During experimentation, you may want to tweak these values to make things run a bit faster until you have a sense of what the right parameters should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "cjG0Kdqs0vh4",
    "outputId": "3f857e0a-87c9-464c-aed2-9edc288fdb5e",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "eval_results = evaluate_topic_models(dtm,\n",
    "                                     varying_parameters=var_params,\n",
    "                                     constant_parameters=const_params,\n",
    "                                     return_models=True)\n",
    "eval_results[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation results are a list with pairs of hyperparameters and their evaluation results for each metric. Additionally, there is the generated model for each hyperparameter set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofoR2i6M0vh8"
   },
   "source": [
    "## results by n_topics\n",
    "\n",
    "We now use [results_by_parameter()](api.rst#tmtoolkit.topicmod.evaluate.results_by_parameter), which takes the \"raw\" evaluation results and sorts them by a specific hyperparameter, in this case `n_topics`. This is important because this is the way that the function for visualizing evaluation results, [plot_eval_results()](api.rst#tmtoolkit.topicmod.visualize.plot_eval_results), expects the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "TfVQEr4x0vh_",
    "outputId": "de25794b-17a7-4e5b-e69e-f4e570a11a3d",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "eval_results_by_ntopics = results_by_parameter(eval_results, 'n_topics')\n",
    "eval_results_by_ntopics[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_0BTC-0S0viK"
   },
   "source": [
    "We can now see the results for each metric across the specified range of number of topics using [plot_eval_results()](api.rst#tmtoolkit.topicmod.visualize.plot_eval_results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "gx-5ab2L0viL",
    "outputId": "8d8a4c5e-2602-424f-c65b-a842d6221bf1",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.visualize import plot_eval_results\n",
    "\n",
    "plot_eval_results(eval_results_by_ntopics);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xBe6QIz30viT"
   },
   "source": [
    "These charts do not \"elbow\" as cleanly as we would like, but we will set the number of topics, `n_topics`, to about 30. We don't have to generate a model with these hyperparameters again, because it's already in the evaluation results (thanks to `return_models=True`). We extract the model from there in order to use it in the rest of the chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bap7FMZ50viZ",
    "outputId": "68f4c909-1bff-4873-f83e-69a1c21983f0",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "best_k = 26\n",
    "best_tm = [m for k, m in eval_results_by_ntopics if k == best_k][0]['model']\n",
    "best_tm.n_topics, best_tm.alpha, best_tm.eta  # just to make sure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uKYt1Gb0vmv"
   },
   "source": [
    "### Interactive visualization with pyLDAVis\n",
    "\n",
    "The [pyLDAVis package](https://pyldavis.readthedocs.io/) offers a great interactive tool to explore a topic model. The tmtoolkit function [parameters_for_ldavis()](api.rst#tmtoolkit.topicmod.visualize.generate_wordclouds_for_document_topics) allows to prepare your topic model data for this package so that you can easily pass it on to pyLDAVis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moDxDnXj0vmw"
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.visualize import parameters_for_ldavis\n",
    "\n",
    "ldavis_params = parameters_for_ldavis(best_tm.topic_word_,\n",
    "                                      best_tm.doc_topic_,\n",
    "                                      dtm,\n",
    "                                      vocab)\n",
    "try:\n",
    "    import pyLDAvis\n",
    "except ModuleNotFoundError:\n",
    "    !pip install pyldavis\n",
    "    import pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.prepare(**ldavis_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzgrRDhx0vie"
   },
   "source": [
    "### Generating labels for topics\n",
    "\n",
    "In topic modeling, topics are numbered because they're *abstract* – they're simply a probability distribution across all words in the vocabulary. Still, it's useful to give them labels for better identification. The function [generate_topic_labels_from_top_words()](api.rst#tmtoolkit.topicmod.model_stats.generate_topic_labels_from_top_words) is very useful for that, as it finds labels according to the most \"relevant\" words in each topic. We'll later see how we can identify the most relevant words per topic using a special [relevance statistic](#Topic-word-relevance). Note that you can adjust the weight of the relevance measure for the ranking by using the parameter `lambda_` which is in range $[0, 1]$.\n",
    "\n",
    "The function requires at least the topic-word and document-topic distributions from the model, the document lengths and the vocabulary. It then finds the minimum number of relevant words that uniquely label each topic. You can also use a fixed number for that minimum number with the parameter `n_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "yD1Ut4t20vik",
    "outputId": "7e0ab9f6-b205-4f40-dc1c-a5dcda70d8c6",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.bow.bow_stats import doc_lengths\n",
    "from tmtoolkit.topicmod.model_stats import generate_topic_labels_from_top_words\n",
    "\n",
    "doc_lengths = doc_lengths(dtm)\n",
    "topic_labels = generate_topic_labels_from_top_words(\n",
    "    best_tm.topic_word_,\n",
    "    best_tm.doc_topic_,\n",
    "    doc_lengths,\n",
    "    vocab,\n",
    "    lambda_=0.6\n",
    ")\n",
    "\n",
    "topic_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxsMlY1p0viq"
   },
   "source": [
    "As we can see, two words are necessary to label each topic uniquely. By default, each label is prefixed with a number. You can change that with the parameter `labels_format`.\n",
    "\n",
    "Let's have a look at the top words for a specific topic. We can use [ldamodel_top_topic_words()](api.rst#tmtoolkit.topicmod.model_io.ldamodel_top_topic_words) for that from the module [topicmod.model_io](api.rst#module-tmtoolkit.topicmod.model_io), which we will have a closer look at [later](#Displaying-and-exporting-topic-modeling-results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "tdViR68F0vir",
    "outputId": "b8f95d93-9096-43e8-ae05-ac08752cb866",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_io import ldamodel_top_topic_words\n",
    "\n",
    "top_topic_word = ldamodel_top_topic_words(best_tm.topic_word_,\n",
    "                                          vocab,\n",
    "                                          row_labels=topic_labels)\n",
    "top_topic_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWOGsr1O0vi1"
   },
   "source": [
    "### Marginal topic and word distributions\n",
    "\n",
    "We'll now focus on the marginal topic and word distributions. Let's get the marginal topic distribution first by using [marginal_topic_distrib()](api.rst#tmtoolkit.topicmod.model_stats.marginal_topic_distrib):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "NcKdDQwx0vi2",
    "outputId": "991df222-21ec-4a31-e32b-ff7baba5cc9b",
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_stats import marginal_topic_distrib\n",
    "\n",
    "marg_topic = marginal_topic_distrib(best_tm.doc_topic_, doc_lengths)\n",
    "marg_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "waKzdPAX0vjA"
   },
   "source": [
    "The marginal topic distribution can be interpreted as the \"importance\" of each topic for the whole corpus. Let's get the sorted indices into `topic_labels` with `np.argsort()` and get the top five topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "1ICrmFJG0vjF",
    "outputId": "c4111099-a6a4-464d-c1a3-fd5545359b0f",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# np.argsort() gives ascending order, hence reverse via [::-1]\n",
    "topic_labels[np.argsort(marg_topic)[::-1][:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6TyZkMF0vjL"
   },
   "source": [
    "Likewise, we can get the marginal word distribution with [marginal_word_distrib()](api.rst#tmtoolkit.topicmod.model_stats.marginal_word_distrib) from the model's topic-word distribution and the marginal topic distribution. We'll use this to list the most probable words for the corpus. As expected, these are mostly quite common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "EfC7vp6G0vjM",
    "outputId": "b996185c-5a14-4ab6-98e6-53bc6be6fcb6",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_stats import marginal_word_distrib\n",
    "\n",
    "marg_word = marginal_word_distrib(best_tm.topic_word_, marg_topic)\n",
    "vocab[np.argsort(marg_word)[::-1][:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XUYURIxC0vjQ"
   },
   "source": [
    "Two helper functions exist for this purpose: [most_probable_words()](api.rst#tmtoolkit.topicmod.model_stats.most_probable_words) and [least_probable_words()](api.rst#tmtoolkit.topicmod.model_stats.least_probable_words) sort the vocabulary according to the marginal probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "7I09QG0M0vjT",
    "outputId": "d6942a49-684b-4fb7-ba2d-364bc4e481ff",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_stats import most_probable_words, least_probable_words\n",
    "\n",
    "most_probable_words(vocab, best_tm.topic_word_,\n",
    "                    best_tm.doc_topic_, doc_lengths,\n",
    "                    n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "eKc3sS8H0vjb",
    "outputId": "7ddfe65c-b5b0-4d1e-b2a9-c50cc8c400e9",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "least_probable_words(vocab, best_tm.topic_word_,\n",
    "                     best_tm.doc_topic_, doc_lengths,\n",
    "                     n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dzd2Z98r0vjg"
   },
   "source": [
    "### Word distinctiveness and saliency\n",
    "\n",
    "Word *distinctiveness* and *saliency* (see below) help to identify the most \"informative\" words in a corpus given its topic model. Both measures are introduced in [Chuang et al. 2012](https://dl.acm.org/citation.cfm?id=2254572).\n",
    "\n",
    "Word distinctiveness is calculated for each word $w$ as\n",
    "\n",
    "$\\text{distinctiveness}(w) = \\sum_T(P(T|w) \\log \\frac{P(T|w)}{P(T)})$.\n",
    "\n",
    "where $P(T)$ is the marginal topic distribution and $P(T|w)$ is the probability of a topic given a word $w$.\n",
    "\n",
    "We can calculate this measure using [word_distinctiveness()](api.rst#tmtoolkit.topicmod.model_stats.word_distinctiveness). To use this measure directly to rank words, we can use [most_distinct_words()](api.rst#tmtoolkit.topicmod.model_stats.most_distinct_words) and [least_distinct_words()](api.rst#tmtoolkit.topicmod.model_stats.least_distinct_words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "zuuCFEBL0vjg",
    "outputId": "240c4eef-3a1d-4d42-868b-f9c499e5e1d1",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_stats import word_distinctiveness, \\\n",
    "    most_distinct_words, least_distinct_words\n",
    "\n",
    "word_distinct = word_distinctiveness(best_tm.topic_word_, marg_topic)\n",
    "word_distinct[:10]   # first 10 words in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "6kNrWudE0vjp",
    "outputId": "fc3b5375-1f03-4488-e6ea-1b72e12efc54",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "most_distinct_words(vocab, best_tm.topic_word_,\n",
    "                    best_tm.doc_topic_, doc_lengths,\n",
    "                    n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "tsPkRucB0vjt",
    "outputId": "0f0a6d6d-3d8c-4c12-fb78-4057373fbaf2",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "least_distinct_words(vocab, best_tm.topic_word_,\n",
    "                     best_tm.doc_topic_, doc_lengths,\n",
    "                     n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwCBN2BA0vj5"
   },
   "source": [
    "Word *saliency* weights each words' distinctiveness by it's marginal probability $P(w)$:\n",
    "\n",
    "$\\text{saliency}(w) = P(w) \\cdot \\text{distinctiveness}(w)$.\n",
    "\n",
    "The respective functions in tmtoolkit are [word_saliency()](api.rst#tmtoolkit.topicmod.model_stats.word_saliency), [most_salient_words()](api.rst#tmtoolkit.topicmod.model_stats.most_salient_words) and [least_salient_words()](api.rst#tmtoolkit.topicmod.model_stats.least_salient_words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "E_m050hw0vj6",
    "outputId": "5ab2851c-5a11-44a2-bcd6-03024c761305",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_stats import word_saliency, \\\n",
    "    most_salient_words, least_salient_words\n",
    "\n",
    "word_sal = word_saliency(best_tm.topic_word_, best_tm.doc_topic_, doc_lengths)\n",
    "word_sal[:10]   # first 10 words in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "2dJIASuj0vkB",
    "outputId": "bb711a0e-4935-4400-b5af-84b29b75aa51",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "most_salient_words(vocab, best_tm.topic_word_,\n",
    "                   best_tm.doc_topic_, doc_lengths,\n",
    "                   n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "gm6fq_Ys0vkE",
    "outputId": "a997e5c3-16d4-4b6c-92a9-e9b047740fab",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "least_salient_words(vocab, best_tm.topic_word_,\n",
    "                    best_tm.doc_topic_, doc_lengths,\n",
    "                    n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dt_e-97h0vkL"
   },
   "source": [
    "### Topic-word relevance\n",
    "\n",
    "The topic-word relevance measure as introduced by [Sievert and Shirley 2014](https://www.aclweb.org/anthology/W14-3110/) helps to identify the most relevant words within a topic by also accounting for the marginal probability of each word across the corpus. This is done by integrating a *lift* value, which is the \"ratio of a term's probability within a topic to its marginal probability across the corpus.\" (ibid.)\n",
    "\n",
    "Thus for each word $w$, given a topic-word distribution $\\phi$, a topic $t$ and a weight parameter $\\lambda$, it is calculated as:\n",
    "\n",
    "$\\text{relevance}_{\\phi, \\lambda}(w, t) = \\lambda \\log \\phi_{t,w} + (1-\\lambda) \\log \\frac{\\phi_{t,w}}{p(w)}$.\n",
    "\n",
    "The first term $\\log \\phi_{t,w}$ is the log of the topic-word distribution, the second term $\\log \\frac{\\phi_{t,w}}{p(w)}$ is the *log lift* and $\\lambda$ can be used to control the weight between both terms. The lower $\\lambda$, the more weight is put on the lift term, i.e. the more different are the results from the original topic-word distribution.\n",
    "\n",
    "This measure is implemented in [topic_word_relevance()](api.rst#tmtoolkit.topicmod.model_stats.topic_word_relevance). It returns a matrix of the same shape as the topic-word distribution, i.e. each row represents a topic with a (log-transformed) distribution across all words in the vocabulary. Please note that the lambda parameter ends with an underscore: `lambda_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "VYtGAEgr0vkO",
    "outputId": "e16dded4-54d5-4c45-a48d-1e0b6cdcd86c",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_stats import topic_word_relevance\n",
    "\n",
    "topic_word_rel = topic_word_relevance(best_tm.topic_word_, best_tm.doc_topic_,\n",
    "                                      doc_lengths, lambda_=0.6)\n",
    "topic_word_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzQJQ3b10vkX"
   },
   "source": [
    "To confirm that it's 30 topics across all words in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H2iapXkI0vkY",
    "outputId": "bf92a1e7-e597-4453-c3a0-a46285d98c5e",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "topic_word_rel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPrdyR350vkg"
   },
   "source": [
    "Two functions can be used to get the most or least relevant words for a topic: [most_relevant_words_for_topic()](api.rst#tmtoolkit.topicmod.model_stats.most_relevant_words_for_topic) and [least_relevant_words_for_topic()](api.rst#tmtoolkit.topicmod.model_stats.least_relevant_words_for_topic). You can select the topic with the `topic` parameter which is a **zero-based topic index**.\n",
    "\n",
    "We'll do it for topic with index 4, which is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xF1aMyO80vkh",
    "outputId": "80209cb8-cb64-4a0e-b448-def7fe72fd46",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "topic_labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Q03nyH7M0vkp",
    "outputId": "7837d7fe-b40b-4dc8-8f46-84fe3190c7cc",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_stats import most_relevant_words_for_topic, \\\n",
    "    least_relevant_words_for_topic\n",
    "\n",
    "most_relevant_words_for_topic(vocab, topic_word_rel, topic=4, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "1RmwUmXc0vkw",
    "outputId": "801a0b05-3fd7-4890-b8d4-9fe3c5718c07",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "least_relevant_words_for_topic(vocab, topic_word_rel, topic=4, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fbH4u_Du0vkz"
   },
   "source": [
    "### Topic coherence\n",
    "\n",
    "We already used the *coherence* metric ([Mimno et al. 2011](https://dl.acm.org/citation.cfm?id=2145462)) for topic model evaluation. However, this metric cannot only be used to assess the overall quality of a topic model, but also to evaluate the individual topics' coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "tmZddOgG0vkz",
    "outputId": "654a876d-f2ae-4d56-c7dd-1d1b927603de"
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.evaluate import metric_coherence_mimno_2011\n",
    "\n",
    "# use top 20 words per topic for metric\n",
    "coh = metric_coherence_mimno_2011(best_tm.topic_word_, dtm, top_n=20)\n",
    "coh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aqdkXk7E0vk3"
   },
   "source": [
    "This generates a coherence value for each topic. Let's show the distribution of these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "BS5UKf2T0vk3",
    "outputId": "942be437-fffb-4d9b-96be-5ed8e657db92",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(coh, bins=20)\n",
    "plt.xlabel('coherence')\n",
    "plt.ylabel('n')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpHcb9Yk0vk8"
   },
   "source": [
    "And print the best and worst topics according to this metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "kJ7Nf0hJ0vk9",
    "outputId": "51263c36-51dd-4848-b07d-4738f78f80eb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "top10_t_indices = np.argsort(coh)[::-1][:5]\n",
    "bottom10_t_indices = np.argsort(coh)[:5]\n",
    "\n",
    "topic_labels[top10_t_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ce4osHrF0vk_",
    "outputId": "101d2681-428c-4da8-ecd5-1dd14954341c"
   },
   "outputs": [],
   "source": [
    "topic_labels[bottom10_t_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "akxEPKhF0vlD"
   },
   "source": [
    "More coherence metrics can be used with the function [metric_coherence_gensim()](api.rst#tmtoolkit.topicmod.evaluate.metric_coherence_gensim). This requires that [gensim](https://radimrehurek.com/gensim/) is installed. Furthemore, most metrics require that a parameter `texts` is passed which is the tokenized text that was used to create the document-term matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELRVUOaj0vlD"
   },
   "source": [
    "### Filtering topics\n",
    "\n",
    "With the function [filter_topics()](api.rst#tmtoolkit.topicmod.model_stats.filter_topics), you can filter the topics according to their topic-word distribution and the following search criteria:\n",
    "\n",
    "- `search_pattern`: one or more search patterns according to the [common parameters for pattern matching](preprocessing.ipynb#Common-parameters-for-pattern-matching-functions)\n",
    "- `top_n`: pattern match(es) must occur in the first `top_n` most probable words in the topic\n",
    "- `thresh`: matched words' probability must be above this threshold\n",
    "\n",
    "You must specify at least one of `top_n` and `thresh`, but you can also specify both. The function returns an array of topic indices (which start with zero!).\n",
    "\n",
    "Let's find all topics that have the word \"police\" in the top 5 most probable words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A691x2-h0vlE",
    "outputId": "a2fc745d-ce8b-4881-8126-134560725ea3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_stats import filter_topics\n",
    "\n",
    "found_topics = filter_topics('finance', vocab,\n",
    "                             best_tm.topic_word_, top_n=5)\n",
    "found_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VfQJTQJG0vlI"
   },
   "source": [
    "We can use these indices with our `topic_labels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GuLta7XH0vlI",
    "outputId": "6b196e14-e439-466e-9611-e595730122af",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "topic_labels[found_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGWIPUYx0vlM"
   },
   "source": [
    "Next, we want to select all topics where *any* of the words matched by the glob patterns (`match_type='glob'`) `\"trump\"` *or* `\"russia*\"` achieve at least a probability of 0.01 (`thresh=0.01`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "l0YXN2zW0vlN",
    "outputId": "b2d63b36-9130-4750-892f-3bf6cfcf8ea7",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "found_topics = filter_topics(['finance', 'contract*'], vocab,\n",
    "                             best_tm.topic_word_, thresh=0.01, match_type='glob')\n",
    "topic_labels[found_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kUJONQqr0vlR"
   },
   "source": [
    "When we specify `cond='all'`, *all* patterns must have at least one match (here in the top 50 list of words per topic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Gqkpf4Vn0vlT",
    "outputId": "7a22c2c1-2a4b-4f66-c07c-026a27abb4b6",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "found_topics = filter_topics(['finance', 'contract*'], vocab,\n",
    "                             best_tm.topic_word_, top_n=50, match_type='glob',\n",
    "                             cond='all')\n",
    "topic_labels[found_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgIsGwaS0vlg"
   },
   "source": [
    "### Excluding topics\n",
    "\n",
    "It is often the case that some topics of a topic model rank a lot of uninformative (e.g. very common) words the highest. This results in some uninformative topics, which you may want to exclude from further analysis. Note that if a large fraction of topics seems uninformative, it points to a problem with your topic model and/or your preprocessing steps. You should [evaluate](#Evaluation-of-topic-models) your candidate models carefully with the mentioned metrics and/or adjust your text preprocessing pipeline.\n",
    "\n",
    "The function [exclude_topics()](api.rst#tmtoolkit.topicmod.model_stats.exclude_topics) allows to remove a specified set of topics from the document-topic and topic-word distributions. You need to pass the **zero-based** indices of the topics that you want to remove, and both distributions.\n",
    "\n",
    "In this example, I identified the following topics as uninformative (by looking at the top ranked words either by topic-word distribution or topic-word relevance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "l4nywyY40vlq",
    "outputId": "405cbbee-3c59-4af8-c78a-59d473350f5f",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "topic_labels[bottom10_t_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwrGKNPO0vls"
   },
   "source": [
    "We can now pass these indices to [exclude_topics()](api.rst#tmtoolkit.topicmod.model_stats.exclude_topics) along with the topic model distributions. We'll get back new, filtered, distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "f-3F96J90vlu",
    "outputId": "629b6a3d-091a-44e0-f6d1-879ed8384ccb",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_stats import exclude_topics\n",
    "\n",
    "new_doc_topic, new_topic_word, new_topic_mapping = \\\n",
    "    exclude_topics(uninform_topics, best_tm.doc_topic_,\n",
    "                best_tm.topic_word_, return_new_topic_mapping=True)\n",
    "new_doc_topic.shape, new_topic_word.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2k_bwA20vlw"
   },
   "source": [
    "We can see in the new distributions' shapes that we now have 45 instead of 50 topics, because we removed five of them. We shouldn't forget to also update the topic labels and remove the unwanted topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "laksfCZx0vlx",
    "outputId": "7329d157-2f3e-4c05-8d93-83414a26cef9",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "new_topic_labels = np.delete(topic_labels, uninform_topics)\n",
    "new_topic_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uES92CG0vl0"
   },
   "source": [
    "## Displaying topic modeling results\n",
    "\n",
    "The [topicmod.model_io](api.rst#module-tmtoolkit.topicmod.model_io) module provides several functions for displaying and exporting topic modeling results, i.e. results derived from the document-topic and topic-word distribution of a given topic model.\n",
    "\n",
    "We already used [ldamodel_top_topic_words()](api.rst#tmtoolkit.topicmod.model_io.ldamodel_top_topic_words) briefly, which generates a dataframe with the top words from a topic-word distribution. You can also use the topic-word relevance matrix instead. With `top_n` we can control the number of top words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "pra_Fppa0vl1",
    "outputId": "f2c9ab46-2746-4316-8da3-4f8ba44e14e0",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# using relevance matrix here and showing only the first 3 topics\n",
    "ldamodel_top_topic_words(topic_word_rel, vocab, top_n=5)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vL0bSpoL0vl3"
   },
   "source": [
    "Note that the values in parantheses are the corresponding values from the matrix for that word in that topic. They're negative because of the log transformation that is applied in the topic-word relevance measure.\n",
    "\n",
    "A similar function can be used for the document-topic distribution: [ldamodel_top_doc_topics()](api.rst#tmtoolkit.topicmod.model_io.ldamodel_top_doc_topics). Here, `top_n` controls the number of top-ranked topics to export. This time, we use the filtered document-topic distribution `new_doc_topics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "xInkNFyD0vl4",
    "outputId": "28ab6bae-0364-44f3-9e3f-6e2c488fe1cf",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_io import ldamodel_top_doc_topics\n",
    "\n",
    "ldamodel_top_doc_topics(best_tm.doc_topic_, doc_labels, top_n=3,\n",
    "                        topic_labels=topic_labels)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CmE58wRl0vl6"
   },
   "source": [
    "Let's have a look at one of these documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "WguELHW00vl6",
    "outputId": "178ee4e2-e8c2-4da3-9956-6bcbb94853e3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(corpus['10046'][:500], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyZxl5gt0vl-"
   },
   "source": [
    "There are also two functions that generate datatables for the full topic-word and document-topic distributions: [ldamodel_full_topic_words()](api.rst#tmtoolkit.topicmod.model_io.ldamodel_full_topic_words) and [ldamodel_full_doc_topics()](api.rst#tmtoolkit.topicmod.model_io.ldamodel_full_doc_topics). The output of both functions is naturally quite big, as long as you're not working with a \"toy dataset\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "id": "lSFNH2sj0vl-",
    "outputId": "6092260c-0dd0-46e5-8026-387f638bf7c3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_io import ldamodel_full_topic_words\n",
    "\n",
    "datatable_topic_word = ldamodel_full_topic_words(best_tm.topic_word_,\n",
    "                                                 vocab,\n",
    "                                                 row_labels=topic_labels)\n",
    "# displaying only the first 5 topics with the first\n",
    "# 10 words from the vocabulary (which are all numbers)\n",
    "#datatable_topic_word[:5, :10]\n",
    "datatable_topic_word[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "WVwFOblv0vmB",
    "outputId": "754d37dd-8ae5-4d44-dbb8-37a19bce67ca",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_io import ldamodel_full_doc_topics\n",
    "\n",
    "datatable_doc_topic = ldamodel_full_doc_topics(best_tm.doc_topic_,\n",
    "                                               doc_labels,\n",
    "                                               topic_labels=topic_labels)\n",
    "# displaying only the first 3 documents with the first\n",
    "# 5 topics\n",
    "#datatable_doc_topic[:3, :5]\n",
    "datatable_doc_topic[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CPD3eOTS0vmE"
   },
   "source": [
    "For quick inspection of topics there's also a pair of print functions. We already used [print_ldamodel_topic_words()](api.rst#tmtoolkit.topicmod.model_io.print_ldamodel_topic_words), but we haven't tried [print_ldamodel_doc_topics()](api.rst#tmtoolkit.topicmod.model_io.print_ldamodel_doc_topics) yet. This prints the `top_n` most probable topics for each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "sLtMhP8S0vmG",
    "outputId": "b5c11d57-c000-4566-abd0-0df6e8078823",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_io import print_ldamodel_doc_topics\n",
    "\n",
    "# subsetting new_doc_topic and doc_labels to get only the first\n",
    "# five documents\n",
    "print_ldamodel_doc_topics(best_tm.doc_topic_[:5, :], doc_labels[:5],\n",
    "                          val_labels=topic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ma1CFeoy0vmQ"
   },
   "source": [
    "## Visualizing topic models\n",
    "\n",
    "The [topicmod.visualize](api.rst#visualize-topic-models-and-topic-model-evaluation-results) module contains several functions to visualize topic models and evaluation results. We've already used [plot_eval_results()](api.rst#tmtoolkit.topicmod.visualize.plot_eval_results) during [topic model evaluation](#Evaluation-of-topic-models) so we'll now focus on visualizing topic models.\n",
    "\n",
    "### Heatmaps\n",
    "\n",
    "Let's start with heatmap visualizations of document-topic or topic-word distributions from our topic model. This can be done with [plot_doc_topic_heatmap()](api.rst#tmtoolkit.topicmod.visualize.plot_doc_topic_heatmap) and [plot_topic_word_heatmap()](api.rst#tmtoolkit.topicmod.visualize.plot_topic_word_heatmap) respectively. Both functions draw on a [matplotlib](https://matplotlib.org/) figure and *Axes* object, which you must create before using these functions.\n",
    "\n",
    "Heatmap visualizations essentially shade cells in a 2D matrix (like the document-topic or topic-word distributions) according to their value, i.e. the respective probability for a topic in a given document or a word in a given topic. Since these matrices are usually quite large, i.e. with hundreds of rows and/or columns, it doesn't make sense to plot a heatmap of the whole matrix, but rather a certain subset of interest. When we want to visualize a document-topic distribution, we can optionally select a subset of the documents with the `which_documents` parameter and a subset of the topics with the `which_topics` parameter. Let's draw a heatmap of a subset of documents across all topics at first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "colab_type": "code",
    "id": "rQp-hJNj0vmS",
    "outputId": "0b87cfb7-90c9-43e3-a687-566764cac7d2",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tmtoolkit.topicmod.visualize import plot_doc_topic_heatmap\n",
    "\n",
    "# create a figure of certain size and\n",
    "# Axes object to draw on\n",
    "fig, ax = plt.subplots(figsize=(32, 8))\n",
    "\n",
    "which_docs = list(corpus.keys())[:10]\n",
    "\n",
    "plot_doc_topic_heatmap(fig, ax, best_tm.doc_topic_, doc_labels,\n",
    "                       topic_labels=topic_labels,\n",
    "                       which_documents=which_docs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "colab_type": "code",
    "id": "STAB54dJ0vmV",
    "outputId": "f0039f5c-1c8f-41ef-e79d-9f51436984d1",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 8))\n",
    "\n",
    "which_topics = [\n",
    "    '10_employee_retirement',\n",
    "    '13_appointing_settlement',\n",
    "    '15_december_red',\n",
    "    '18_station_asap',\n",
    "    '19_delivery_strategic'\n",
    "]\n",
    "\n",
    "plot_doc_topic_heatmap(fig, ax, best_tm.doc_topic_, doc_labels,\n",
    "                       topic_labels=topic_labels,\n",
    "                       which_documents=which_docs,\n",
    "                       which_topics=which_topics);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWkeljpQ0vmW",
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Similarily, we can work with [plot_topic_word_heatmap()](api.rst#tmtoolkit.topicmod.visualize.plot_topic_word_heatmap) to visualize a topic-word distribution. We can also select a subset of topics and words from the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "colab_type": "code",
    "id": "673Z1am90vmX",
    "outputId": "66ac9209-d7e5-4252-b85a-254ec59e6c98",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.visualize import plot_topic_word_heatmap\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "which_words = ['finance', 'budget', 'project', 'contract']\n",
    "\n",
    "plot_topic_word_heatmap(fig, ax, best_tm.topic_word_, vocab,\n",
    "                        topic_labels=topic_labels,\n",
    "                        which_topics=which_topics,\n",
    "                        which_words=which_words);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yv6qhC0I0vmZ"
   },
   "source": [
    "Note that there's also a generic heatmap plotting function [plot_heatmap()](api.rst#plot-heatmaps-for-topic-models) for any kind of 2D matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e8PSsTHv0vma"
   },
   "source": [
    "### Word clouds\n",
    "\n",
    "Thanks to the [wordlcloud package](https://pypi.org/project/wordcloud/), topic-word and document-topic distributions can also be visualized as \"word clouds\" with tmtoolkit. The function [generate_wordclouds_for_topic_words()](api.rst#tmtoolkit.topicmod.visualize.generate_wordclouds_for_topic_words) generates a word cloud for each topic by scaling a topic's word by its probability (weight). You can choose to display only the top `top_n` words per topic. The result of this function will be a dictionary mapping topic labels to the respective word cloud image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "igAfqUQb0vma",
    "outputId": "c7c41a65-291c-4772-e4ce-cd2d42d9812a"
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.visualize import generate_wordclouds_for_topic_words\n",
    "\n",
    "# some options for wordcloud output\n",
    "img_w = 400   # image width\n",
    "img_h = 300   # image height\n",
    "\n",
    "topic_clouds = generate_wordclouds_for_topic_words(\n",
    "    new_topic_word, vocab_bg,\n",
    "    top_n=20, topic_labels=new_topic_labels,\n",
    "    width=img_w, height=img_h\n",
    ")\n",
    "\n",
    "# show all generated word clouds\n",
    "topic_clouds.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pvlS1CDQ0vmg"
   },
   "source": [
    "Let's select specific topics and display their word cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "_jnC6h0U0vmj",
    "outputId": "68a676f5-ae0b-4a34-a07c-851ccd963ff8"
   },
   "outputs": [],
   "source": [
    "topic_clouds['13_appointing_settlement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "Kq9Qu7si0vmk",
    "outputId": "84b964d7-3d1b-4baa-fba3-9f2e808840b6"
   },
   "outputs": [],
   "source": [
    "topic_clouds['10_employee_retirement']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMmAtJcM0vmm"
   },
   "source": [
    "The same can be done for the document-topic distribution using [generate_wordclouds_for_document_topics()](api.rst#tmtoolkit.topicmod.visualize.generate_wordclouds_for_document_topics). Here, a word cloud for each document will be generated that contains the `top_n` most probable topics for this document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "McXp5Cmo0vmn",
    "outputId": "3f24f25e-8c92-4050-d3e5-c28a351dbba6"
   },
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.visualize import generate_wordclouds_for_document_topics\n",
    "\n",
    "doc_clouds = generate_wordclouds_for_document_topics(\n",
    "    new_doc_topic, doc_labels, topic_labels=new_topic_labels,\n",
    "    top_n=5, width=img_w, height=img_h)\n",
    "\n",
    "# show only the first 5 documents for\n",
    "# which word clouds were generated\n",
    "list(doc_clouds.keys())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6eD3h5o0vmp"
   },
   "source": [
    "To display a specific document's topic word cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "tnZM2cwN0vmq",
    "outputId": "2c384d12-c2dc-4d96-ab3b-2116bc89c410"
   },
   "outputs": [],
   "source": [
    "doc_clouds['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fxr4PvTr05vC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "topic_modeling_Russian_FB_ads.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
